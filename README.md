# ConsistenceHashTree
一致性Hash算法


<pre>
     一致性哈希算法长用于负载均衡中要求资源被均匀的分布到所有节点上，并且对资源的请求能快速
  路由到对应的节点上。
</pre>

<pre>
具体应用场景例子：
      1）Memcache集群，要求存储在各种数据均匀的存储到集群的各个节点上，访问这些数据时能够
        快速的路由到集群中对应存放该数据的节点上；并且要求增删节点对整个集群的影响很小，不
        至于有大的动荡造成整体负载的不稳定。
      2）RPC过程中服务提供者做N个节点的集群部署，为了能在服务上维护一些业务状态，希望同一
        种请求每次都落到同一台服务上。
</pre>

![](https://i.imgur.com/I9tO8Ov.png)

增加节点Node4

![](https://i.imgur.com/7IAe0dS.png)

<pre>
     比如有{N0, N1, N2}三个节点，陆续有多个资源要分配到这3个节点上，如何尽可能均匀的分配
     到这些节点上？

     我们分配节点最简单的办法是取余算法，即有3个节点，资源key=5, 5%3=2，选取N2，key=3，
     3%3=0，选取N0。虽然简单，但有个缺点，如果节点数增加或减少，就会有大量的key不命中，造
     成请求压力转移，可能对系统整体有很大的影响，甚至发生宕机危险。

     而一致性哈希算法增加或减少节点，只会引起少部分key不命中，如下图，增加一个Node4节点，
     只会将加粗部分的key值从Node1(10.0.0.0:91002)移到Node4(10.0.0.0:91003)，对集群
     影响很小。

     Java实现中用什么表示Hash环好呢？经对比，用TreeMap的时间复杂度是O(logN)，相对效率
     比较高，因为TreeMap使用了红黑树结构存储实体对象。

     Hash算法的选择上，首先我们考虑简单的String.HashCode()方法，这个算法的缺点是，相似
     的字符串如N1(10.0.0.0:91001)，N2(10.0.0.0:91002)，N3(10.0.0.0:91003)，哈希值
     也很相近，造成的结果是节点在Hash环上分布很紧密，导致大部分Key值落到了N0上，节点资源
     分布不均。一般我们采用FNV1_32_HASH、KETAMA_HASH等算法，KETAMA_HASH是MemCache集群
     默认的实现方法，这些算法效果要好得多，会使N0，N1，N2的Hash值更均匀的分布在环上。
</pre>